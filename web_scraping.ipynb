{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/site-packages (from requests) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests) (3.3)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: selenium in /usr/local/lib/python3.9/site-packages (4.3.0)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /usr/local/lib/python3.9/site-packages (from selenium) (1.26.11)\n",
      "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.9/site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.9/site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: async-generator>=1.9 in /usr/local/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: outcome in /usr/local/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.9/site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /usr/local/lib/python3.9/site-packages (from urllib3[secure,socks]~=1.26->selenium) (37.0.4)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /usr/local/lib/python3.9/site-packages (from urllib3[secure,socks]~=1.26->selenium) (22.0.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.9/site-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/site-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: webdriver-manager in /usr/local/lib/python3.9/site-packages (3.8.3)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/site-packages (from webdriver-manager) (0.20.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from webdriver-manager) (4.64.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from webdriver-manager) (2.28.1)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (2.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->webdriver-manager) (2022.6.15)\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/usr/local/opt/python@3.9/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install beautifulsoup4 \n",
    "!pip3 install requests\n",
    "!pip3 install selenium\n",
    "!pip3 install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "\n",
    "def scrape_scroll_articles(link, tag, class_name, scroll_num, sleep_time):\n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "    driver.get(link)\n",
    "\n",
    "    for i in range(1,scroll_num):\n",
    "        driver.execute_script(\"window.scrollTo(1,50000)\")\n",
    "        time.sleep(sleep_time)\n",
    "\n",
    "    file = open('DS.html', 'w')\n",
    "    file.write(driver.page_source)\n",
    "    file.close()\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    data = open('./DS.html','r')\n",
    "    soup = BeautifulSoup(data,\"html.parser\")\n",
    "    results = soup.find_all(tag, {'class': class_name}) if class_name != None else soup.find_all(tag)\n",
    "    \n",
    "    urls = []\n",
    "    if tag != \"div\":\n",
    "        for result in results:\n",
    "            link = result[\"href\"]\n",
    "            urls.append(link)\n",
    "    else:\n",
    "        for result in results:\n",
    "            link = result.find(\"a\")[\"href\"]\n",
    "            urls.append(link)\n",
    "    \n",
    "    return urls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_article_aljazirah(links, section):\n",
    "    content = []\n",
    "    title = []\n",
    "    author = []\n",
    "    urls = []\n",
    "    sec = []\n",
    "    for url in links:\n",
    "        res = get(url)\n",
    "        html_soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        article_containers = html_soup.find_all('p')\n",
    "        article_title = html_soup.find('h1', {\"class\": \"entry-title title flipboard-title\"})\n",
    "        article_author = article_containers[2].get_text() if article_containers[2] != None else \"N/A\"\n",
    "        article_containers = article_containers[3:-2] if article_containers[3:-2] != None else \"N/A\"\n",
    "        article_title = article_title.get_text() if article_title != None else \"N/A\"\n",
    "        urls.append(url)\n",
    "        author.append(article_author)\n",
    "        content.append(\" \".join([data.get_text() for data in article_containers]))\n",
    "        title.append(article_title)\n",
    "        sec.append(section)\n",
    "    return {\"url\": urls, \"title\": title, \n",
    "\t\t\"author\": author, \"content\": content, \"section\": sec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "links = {\n",
    "    \"local\":\"https://www.al-jazirahonline.com/category/%d8%a7%d9%84%d9%85%d9%85%d9%84%d9%83%d8%a9/\",\n",
    "    \"world\":\"https://www.al-jazirahonline.com/category/world/\",\n",
    "    \"sport\":\"https://www.al-jazirahonline.com/category/sport/\",\n",
    "    \"women\":\"https://www.al-jazirahonline.com/category/%d8%a7%d9%84%d9%85%d8%b1%d8%a3%d8%a9/\",\n",
    "    \"culture\":\"https://www.al-jazirahonline.com/category/%d8%a7%d9%84%d9%85%d8%ac%d8%aa%d9%85%d8%b9/\"\n",
    "}\n",
    "data = {\"url\": [], \"title\": [], \n",
    "\t\t\"author\": [], \"content\": [], \"section\": []}\n",
    "for section, link in links.items():\n",
    "    print(section)\n",
    "    articles_urls = []\n",
    "    for i in range(1, 200):\n",
    "        if i == 1:\n",
    "            response = requests.get(link)\n",
    "        else:\n",
    "              response = requests.get(f\"{link}page/{i}\")\n",
    "        aljazirah_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        page_links = aljazirah_soup.find_all(\"a\", {\"class\": \"mask-img\"})\n",
    "        for url in page_links:\n",
    "            articles_urls.append(url[\"href\"])\n",
    "    section_articles = scrape_article_aljazirah(articles_urls, section)\n",
    "    data[\"url\"].extend(section_articles[\"url\"])\n",
    "    data[\"title\"].extend(section_articles[\"title\"])\n",
    "    data[\"author\"].extend(section_articles[\"author\"])\n",
    "    data[\"content\"].extend(section_articles[\"content\"])\n",
    "    data[\"section\"].extend(section_articles[\"section\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "df.to_csv(\"al-jazirah.csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1116, 1116, 1116)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['content']), len(data['author']), len(data['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "def scrape_article_okaz(links):\n",
    "    content = []\n",
    "    title = []\n",
    "    author = []\n",
    "    url = []\n",
    "    sec = []\n",
    "    for section, section_urls in links.items():\n",
    "        print(section)\n",
    "        for url in section_urls:\n",
    "            res = get(url)\n",
    "            html_soup = BeautifulSoup(res.text, 'html.parser')\n",
    "            article_containers = html_soup.find('div', {\"class\": \"bodyText\"})\n",
    "            title = html_soup.find('h1')\n",
    "            has_child_nodes = len(article_containers.find_all(\"p\")) != 0\n",
    "            author = html_soup.find(\"ul\", {\"class\": \"list-meta-items header-top show-for-desktop\"})\n",
    "            url.append(url)\n",
    "            author.append(author.find_all(\"li\")[1].get_text())\n",
    "            if has_child_nodes: \n",
    "                content.append(\" \".join([data.get_text() for data in article_containers]))\n",
    "            else:\n",
    "                content.append(article_containers.get_text())\n",
    "            title.append(title.get_text())\n",
    "            if section == \"news\":\n",
    "                sec.append(url.split('/')[4])\n",
    "            else:\n",
    "                sec.append(section)\n",
    "    return {\"url\": url, \"title\": title, \n",
    "\t\t\"author\": author, \"content\": content, \"section\": sec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "\n",
    "session = requests.Session()\n",
    "sections = {190: \"news\", 3: \"sport\", 4: \"economy\", 8: \"culture\"}\n",
    "    \n",
    "articles_urls = {\"news\": [], \"sport\": [], \"economy\": [], \"culture\": []}\n",
    "\n",
    "for section in sections.keys():\n",
    "    for i in range(1, 200):\n",
    "        payload = {\"page\":i, \"section\":section, \"sub_section\":0}\n",
    "        response = session.post('https://www.okaz.com.sa/ajax-more-articles',headers=headers,data=payload)\n",
    "        if response.headers[\"content-type\"].strip().startswith(\"application/json\"):\n",
    "            soup = BeautifulSoup(response.json()[\"html\"],\"html.parser\")\n",
    "        else: soup = BeautifulSoup(response.text,\"html.parser\")\n",
    "        results = soup.find_all(\"div\", {'class': \"update\"}) \n",
    "        \n",
    "        for result in results:\n",
    "            link = result.find(\"a\")[\"href\"]\n",
    "            articles_urls[sections[section]].append(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "news\n",
      "sport\n",
      "economy\n",
      "culture\n"
     ]
    }
   ],
   "source": [
    "data = {\"url\": [], \"title\": [], \n",
    "\t\t\"author\": [], \"content\": [], \"section\": []}\n",
    "\n",
    "section_articles = scrape_article_okaz(articles_urls)\n",
    "data[\"url\"].extend(section_articles[\"url\"])\n",
    "data[\"title\"].extend(section_articles[\"title\"])\n",
    "data[\"author\"].extend(section_articles[\"author\"])\n",
    "data[\"content\"].extend(section_articles[\"content\"])\n",
    "data[\"section\"].extend(section_articles[\"section\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13515 entries, 0 to 13514\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   url      13515 non-null  object\n",
      " 1   title    13515 non-null  object\n",
      " 2   author   13515 non-null  object\n",
      " 3   content  13515 non-null  object\n",
      " 4   section  13515 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 528.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)\n",
    "\n",
    "df.to_csv(\"okaz.csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "\n",
    "def scrape_article_sabq(links, section):\n",
    "    sabq_content = []\n",
    "    sabq_title = []\n",
    "    sabq_author = []\n",
    "    sabq_url = []\n",
    "    sabq_sec = []\n",
    "    for url in links:\n",
    "        res = get(url)\n",
    "        html_soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        article_containers = html_soup.find('div', {\"class\": \"arr--story-page-card-wrapper\"})\n",
    "        title = html_soup.find('h1')\n",
    "        author = html_soup.find(\"h5\")\n",
    "        author = author.get_text() if author != None else \"N/A\"\n",
    "        article_containers = article_containers.get_text() if article_containers != None else \"N/A\"\n",
    "        title = title.get_text() if title != None else \"N/A\"\n",
    "        sabq_url.append(url)\n",
    "        sabq_author.append(author)\n",
    "        sabq_content.append(article_containers)\n",
    "        sabq_title.append(title)\n",
    "        sabq_sec.append(section)\n",
    "    return {\"url\": sabq_url, \"title\": sabq_title, \n",
    "\t\t\"author\": sabq_author, \"content\": sabq_content, \"section\": sabq_sec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports\n",
      "saudia\n",
      "world\n",
      "mylife\n",
      "stations\n",
      "tourism\n",
      "technology\n",
      "cars\n",
      "business\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "sections = [\"sports\", \"saudia\", \"world\", \"mylife\", \"stations\", \"tourism\", \"technology\", \"cars\", \"business\"]\n",
    "data = {\"url\": [], \"title\": [], \n",
    "\t\t\"author\": [], \"content\": [], \"section\": []}\n",
    "for section in sections:\n",
    "    response = requests.get(\"https://sabq.org/api/v1/collections/\" + section + \"?item-type=story&limit=1000\") \n",
    "    links = []\n",
    "    print(section)\n",
    "    for item in response.json()[\"items\"]:\n",
    "        links.append(item[\"story\"][\"url\"])\n",
    "    section_articles = scrape_article_sabq(links, section)\n",
    "    data[\"url\"].extend(section_articles[\"url\"])\n",
    "    data[\"title\"].extend(section_articles[\"title\"])\n",
    "    data[\"author\"].extend(section_articles[\"author\"])\n",
    "    data[\"content\"].extend(section_articles[\"content\"])\n",
    "    data[\"section\"].extend(section_articles[\"section\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8349 entries, 0 to 8348\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   url      8349 non-null   object\n",
      " 1   title    8349 non-null   object\n",
      " 2   author   8349 non-null   object\n",
      " 3   content  8349 non-null   object\n",
      " 4   section  8349 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 326.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>section</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://sabq.org/sports/vtx4t2tf2w</td>\n",
       "      <td>الأولمبي الآسيوي يرحب بطلب المملكة استضافة دور...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>رحب المجلس الأولمبي الآسيوي ومقره دولة الكويت ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://sabq.org/sports/9jr7prlkn4</td>\n",
       "      <td>\"النصر\" و\"الاتفاق\" مهتمان بالمدافع البلجيكى \"ج...</td>\n",
       "      <td>محمد السيد</td>\n",
       "      <td>كشف موقع \"footmercato\" الفرنسي أن البلجيكي جيس...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://sabq.org/sports/ivh1nowgtl</td>\n",
       "      <td>ضمن معسكره في مدينة بوردور .. الأخضر الأولمبي ...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>أجرى المنتخب السعودي تحت 23 عامًا لكرة القدم ،...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://sabq.org/sports/5kp7sl0x1w</td>\n",
       "      <td>كان ضمن اهتمامات \"الاتحاد\" .. \"بن شرقي\" يقترب ...</td>\n",
       "      <td>محمد السيد</td>\n",
       "      <td>كشفت تقارير إعلامية أن المحترف المغربي أشرف بن...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://sabq.org/sports/lyvfk5u786</td>\n",
       "      <td>صربيا تجهز حكام دوري كأس الأمير محمد بن سلمان ...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>دشن حكام دوري كأس الأمير محمد بن سلمان للمحترف...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://sabq.org/sports/8q5gscb7ma</td>\n",
       "      <td>بعد ودية كوكسي .. الاتفاق يستأنف تدريباته وباخ...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>وسط أجواء كثيفة من الضباب استأنف الفريق الأول ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://sabq.org/sports/du56fjofza</td>\n",
       "      <td>قمة الجولة العاشرة تجمع الهلال والنصر.. في ملع...</td>\n",
       "      <td>أحمد سرور</td>\n",
       "      <td>اعتمدت لجنة المسابقات في الرابطة جدول مباريات ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://sabq.org/sports/75d0jgjvr5</td>\n",
       "      <td>انطلاق معسكر برنامج الابتعاث السعودي لتطوير مو...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>انطلق اليوم معسكر برنامج الابتعاث السعودي لتط...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://sabq.org/sports/3yth9rvpv9</td>\n",
       "      <td>قادمًا من الأهلي.. \"السومة\" ينتقل للدوري القطري</td>\n",
       "      <td>سبق</td>\n",
       "      <td>ظفر نادي العربي القطري بخدمات مهاجم الفريق الك...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://sabq.org/sports/7nvhbxuql2</td>\n",
       "      <td>بنظام الإعارة من النصر.. \"قاسم\" يقترب من التوق...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>أشارت تقارير محلية، اليوم الخميس، إلى أن ظهير ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://sabq.org/sports/3yxdwteton</td>\n",
       "      <td>رئيس لجنة الانضباط لـ\"سبق\": النصر قد يستفيد من...</td>\n",
       "      <td>قاسم خبراني</td>\n",
       "      <td>‏أكد المستشار القانوني ورئيس لجنة الانضباط ساب...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://sabq.org/sports/4n9rdek5ez</td>\n",
       "      <td>بطولة Rainbow Six Siege تنطلق غدًا بمجموع جوائ...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>كشف الاتحاد السعودي للرياضات الإلكترونية عن تف...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://sabq.org/sports/vnaakjc6tu</td>\n",
       "      <td>منتخب مصر يضرب موعدًا مع شقيقه السعودي في نهائ...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>ضرب المنتخب المصري تحت 20 عامًا لكرة القدم موع...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://sabq.org/sports/lnvbhukw77</td>\n",
       "      <td>في تجربته الودية الأولى .. الخليج يعبر محطة ال...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>حقق فريق الخليج الأول لكرة القدم، انتصاره الأو...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://sabq.org/sports/bcx8a5mwcw</td>\n",
       "      <td>استعدادًا للموسم الرياضي الجديد 2022-2023 .. ا...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>ينطلق اليوم الأربعاء المعسكر الإعدادي لحكام دو...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://sabq.org/sports/lmsfrf8xi1</td>\n",
       "      <td>الاتفاق يتعادل مع كوكسي الألباني .. في ثاني ود...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>خيم التعادل السلبي بين الفريق الأول لكرة القدم...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://sabq.org/sports/6ndek4gj1d</td>\n",
       "      <td>الأخضر الشاب يكتسح منتخب فلسطين بخماسية.. ويتأ...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>تأهّل المنتخب السعودي تحت 20 عامًا لكرة القدم ...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://sabq.org/sports/zhw51tbgn0</td>\n",
       "      <td>شباب الأهلي الإماراتي يضم مهاجم الهلال السابق ...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>أعلن نادي شباب الأهلي الإماراتي لكرة القدم، ا...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://sabq.org/sports/9n46jrygku</td>\n",
       "      <td>اتحاد القدم يحذّر من استخدام شعاره في الدورات ...</td>\n",
       "      <td>سبق</td>\n",
       "      <td>أكد الاتحاد السعودي لكرة القدم أن ساعات التعلي...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://sabq.org/sports/tfkmlbyrcd</td>\n",
       "      <td>الخبير في القانون الرياضي \"الأمير\": القرار قاب...</td>\n",
       "      <td>قاسم خبراني</td>\n",
       "      <td>توقَّع خبير في القانون الرياضي بعد إسدال الست...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   url  \\\n",
       "0   https://sabq.org/sports/vtx4t2tf2w   \n",
       "1   https://sabq.org/sports/9jr7prlkn4   \n",
       "2   https://sabq.org/sports/ivh1nowgtl   \n",
       "3   https://sabq.org/sports/5kp7sl0x1w   \n",
       "4   https://sabq.org/sports/lyvfk5u786   \n",
       "5   https://sabq.org/sports/8q5gscb7ma   \n",
       "6   https://sabq.org/sports/du56fjofza   \n",
       "7   https://sabq.org/sports/75d0jgjvr5   \n",
       "8   https://sabq.org/sports/3yth9rvpv9   \n",
       "9   https://sabq.org/sports/7nvhbxuql2   \n",
       "10  https://sabq.org/sports/3yxdwteton   \n",
       "11  https://sabq.org/sports/4n9rdek5ez   \n",
       "12  https://sabq.org/sports/vnaakjc6tu   \n",
       "13  https://sabq.org/sports/lnvbhukw77   \n",
       "14  https://sabq.org/sports/bcx8a5mwcw   \n",
       "15  https://sabq.org/sports/lmsfrf8xi1   \n",
       "16  https://sabq.org/sports/6ndek4gj1d   \n",
       "17  https://sabq.org/sports/zhw51tbgn0   \n",
       "18  https://sabq.org/sports/9n46jrygku   \n",
       "19  https://sabq.org/sports/tfkmlbyrcd   \n",
       "\n",
       "                                                title       author  \\\n",
       "0   الأولمبي الآسيوي يرحب بطلب المملكة استضافة دور...          سبق   \n",
       "1   \"النصر\" و\"الاتفاق\" مهتمان بالمدافع البلجيكى \"ج...   محمد السيد   \n",
       "2   ضمن معسكره في مدينة بوردور .. الأخضر الأولمبي ...          سبق   \n",
       "3   كان ضمن اهتمامات \"الاتحاد\" .. \"بن شرقي\" يقترب ...   محمد السيد   \n",
       "4   صربيا تجهز حكام دوري كأس الأمير محمد بن سلمان ...          سبق   \n",
       "5   بعد ودية كوكسي .. الاتفاق يستأنف تدريباته وباخ...          سبق   \n",
       "6   قمة الجولة العاشرة تجمع الهلال والنصر.. في ملع...    أحمد سرور   \n",
       "7   انطلاق معسكر برنامج الابتعاث السعودي لتطوير مو...          سبق   \n",
       "8     قادمًا من الأهلي.. \"السومة\" ينتقل للدوري القطري          سبق   \n",
       "9   بنظام الإعارة من النصر.. \"قاسم\" يقترب من التوق...          سبق   \n",
       "10  رئيس لجنة الانضباط لـ\"سبق\": النصر قد يستفيد من...  قاسم خبراني   \n",
       "11  بطولة Rainbow Six Siege تنطلق غدًا بمجموع جوائ...          سبق   \n",
       "12  منتخب مصر يضرب موعدًا مع شقيقه السعودي في نهائ...          سبق   \n",
       "13  في تجربته الودية الأولى .. الخليج يعبر محطة ال...          سبق   \n",
       "14  استعدادًا للموسم الرياضي الجديد 2022-2023 .. ا...          سبق   \n",
       "15  الاتفاق يتعادل مع كوكسي الألباني .. في ثاني ود...          سبق   \n",
       "16  الأخضر الشاب يكتسح منتخب فلسطين بخماسية.. ويتأ...          سبق   \n",
       "17  شباب الأهلي الإماراتي يضم مهاجم الهلال السابق ...          سبق   \n",
       "18  اتحاد القدم يحذّر من استخدام شعاره في الدورات ...          سبق   \n",
       "19  الخبير في القانون الرياضي \"الأمير\": القرار قاب...  قاسم خبراني   \n",
       "\n",
       "                                              content section  \n",
       "0   رحب المجلس الأولمبي الآسيوي ومقره دولة الكويت ...  sports  \n",
       "1   كشف موقع \"footmercato\" الفرنسي أن البلجيكي جيس...  sports  \n",
       "2   أجرى المنتخب السعودي تحت 23 عامًا لكرة القدم ،...  sports  \n",
       "3   كشفت تقارير إعلامية أن المحترف المغربي أشرف بن...  sports  \n",
       "4   دشن حكام دوري كأس الأمير محمد بن سلمان للمحترف...  sports  \n",
       "5   وسط أجواء كثيفة من الضباب استأنف الفريق الأول ...  sports  \n",
       "6   اعتمدت لجنة المسابقات في الرابطة جدول مباريات ...  sports  \n",
       "7    انطلق اليوم معسكر برنامج الابتعاث السعودي لتط...  sports  \n",
       "8   ظفر نادي العربي القطري بخدمات مهاجم الفريق الك...  sports  \n",
       "9   أشارت تقارير محلية، اليوم الخميس، إلى أن ظهير ...  sports  \n",
       "10  ‏أكد المستشار القانوني ورئيس لجنة الانضباط ساب...  sports  \n",
       "11  كشف الاتحاد السعودي للرياضات الإلكترونية عن تف...  sports  \n",
       "12  ضرب المنتخب المصري تحت 20 عامًا لكرة القدم موع...  sports  \n",
       "13  حقق فريق الخليج الأول لكرة القدم، انتصاره الأو...  sports  \n",
       "14  ينطلق اليوم الأربعاء المعسكر الإعدادي لحكام دو...  sports  \n",
       "15  خيم التعادل السلبي بين الفريق الأول لكرة القدم...  sports  \n",
       "16  تأهّل المنتخب السعودي تحت 20 عامًا لكرة القدم ...  sports  \n",
       "17   أعلن نادي شباب الأهلي الإماراتي لكرة القدم، ا...  sports  \n",
       "18  أكد الاتحاد السعودي لكرة القدم أن ساعات التعلي...  sports  \n",
       "19   توقَّع خبير في القانون الرياضي بعد إسدال الست...  sports  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"sabq.csv\" ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_article_alriyadh(links, section):\n",
    "    content = []\n",
    "    title = []\n",
    "    author = []\n",
    "    url = []\n",
    "    sec = []\n",
    "    for url in links:\n",
    "        res = get(url, verify=False)\n",
    "        html_soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        article_containers = html_soup.find('div', {\"class\": \"col-md-12 article-text\"}).get_text()\n",
    "        title = html_soup.find('h2').get_text()\n",
    "        author = html_soup.find(\"div\", {\"class\": \"col-md-12 col-lg-3\"}).get_text()\n",
    "        url.append(url)\n",
    "        author.append(author)\n",
    "        content.append(article_containers)\n",
    "        title.append(title)\n",
    "        sec.append(section)\n",
    "    return {\"url\": url, \"title\": title, \n",
    "\t\t\"author\": author, \"content\": content, \"section\": sec}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports\n",
      "local\n",
      "world\n",
      "economy\n",
      "culture\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sections = {\"sports\": \"/news.sport\", \"local\": \"/news.local\", \"world\": \"/news.inter\", \"economy\": \"/news.econ\", \"culture\": \"/culture\"}\n",
    "data = {\"url\": [], \"title\": [], \n",
    "\t\t\"author\": [], \"content\": [], \"section\": []}\n",
    "for section, url in sections.items():\n",
    "    print(section)\n",
    "    links = []\n",
    "    for i in range(1, 1000):\n",
    "        response = requests.get(\"https://www.alriyadh.com\" + url + \"?&page=\" + str(i), verify=False) \n",
    "        riyadh_soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        page_links = riyadh_soup.find_all(\"h4\")\n",
    "        for link in page_links:\n",
    "            links.append(\"https://www.alriyadh.com\" + link.find(\"a\")[\"href\"])\n",
    "    section_articles = scrape_article_alriyadh(links, section)\n",
    "    data[\"url\"].extend(section_articles[\"url\"])\n",
    "    data[\"title\"].extend(section_articles[\"title\"])\n",
    "    data[\"author\"].extend(section_articles[\"author\"])\n",
    "    data[\"content\"].extend(section_articles[\"content\"])\n",
    "    data[\"section\"].extend(section_articles[\"section\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2260 entries, 0 to 2259\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   url      2260 non-null   object\n",
      " 1   title    2260 non-null   object\n",
      " 2   author   2260 non-null   object\n",
      " 3   content  2260 non-null   object\n",
      " 4   section  2260 non-null   object\n",
      "dtypes: object(5)\n",
      "memory usage: 88.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"alriyadh.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "okaz = pd.read_csv(\"okaz.csv\", lineterminator='\\n')\n",
    "aljazirah = pd.read_csv(\"al-jazirah.csv\")\n",
    "sabq = pd.read_csv(\"sabq.csv\")\n",
    "alriyadh = pd.read_csv(\"alriyadh.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13515, 5)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "okaz.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8350, 5)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sabq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1116, 5)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aljazirah.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2260, 5)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alriyadh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
